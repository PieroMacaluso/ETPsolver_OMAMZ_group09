\documentclass[11pt, a4paper, leqno]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{libertine} % font bello
\usepackage[paper=a4paper,top=1in,bottom=1.1in,right=1in,left=1in]{geometry} % margini

\usepackage{enumitem} % liste piÃ¹ compatte (se ce ne saranno)
%\setlist[enumerate]{itemsep=0.0em}
\setlist[itemize]{itemsep=0.0em}
\usepackage[compact]{titlesec}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[]{algorithm2e}

\newcommand{\nome}[2]{
\begin{minipage}[t]{0.185\linewidth}
	\centering #1\par
	\centering\small (#2)\par
\end{minipage}
}

% Questo era utile per evidenziare le cose "dubbie e da correggere"
% Poi si elimina il comando cosi' non restano \boh{} in giro
%\usepackage{xcolor}
%\newcommand{\boh}[1]{\textcolor{red}{#1}}

\newcommand{\eqp}[1]{\textit{(eq. \ref{#1})}}
\newcommand{\eq}[1]{\textit{\ref{#1}}}

\begin{document}	
	\begin{center}
		{\huge\textbf{OMA Final Report}}\par
		\vspace{0.3em}
		{\large\textbf{Group 9}}\par
		\vspace{1em}
		\nome{Piero Macaluso}{s252894}
		\nome{Lorenzo Manicone}{s217189}
		\nome{Donato Tortoriello}{s205639}
		\nome{Ludovico Pavesi}{s246422}
		\nome{Alberto Romano}{s254036} % 164371
	\end{center}

	\section{Building conflict matrix}
	
	Was done by taking each couple of exams and counting students enrolled in both. This was agonizingly slow, taking about 20 seconds on istance 6.
	
	Also, it was a mistake since before that it worked differently but the entire data structure has been changed multiple times.
	
	It was later improved by iterating over students once and, for each student, taking every couple of exams they're enrolled in and incrementing the right cell in the conflict matrix.
	
	Finding this performance problem (which appeared by mistake, mind you) required us to use a profiler, but nobody cares about stuff that's really useful in the real world and we'll almost surely use in future (these absurd algorithms... most of us will never see them again).

	\section{Initial solution generation}
	
	\subsection{Random}
	
	Initially we tried generating random starting solutions: that is, to each exam assign a random time slot. This was very fast, but even after thousands of runs we couldn't find even a single feasible solution on ``real'' instances. It worked on the ``test'' instance, however.
	
	\subsection{Greedy 1 (``Extremely Stupid Greedy'')}
	
	We tried to implement a very simplistic greedy algorithm that iterates over each exam, finds the first available time slot by iterating over all time slots and checking conflicts, and placing it there. The aim was mainly to see what a feasible solution ``looked like''.
	
	%\begin{algorithm}[H]
	%	%\KwData{dati}
	%	%\KwResult{risultato}
	%	%initialization\;
	%	\
	%	\ForEach{exam}{
	%		\While{}{
	%			\If{exam can be scheduled in timeslot}{
	%				assign exam to timeslot\;
	%				break (evaluate next exam)\;
	%			}
	%		}
	%	}
	%	\caption{The very simplistic greedy algorithm}
	%\end{algorithm}

	This never yielded a feasible solution for any of the real instances, as when it got near the end of the exam list there were no more non-conflicting time slots available.
	
	It should be noted that this algorithm is deterministic, as it always produced the same solution.
	
	\subsection{Greedy 2 (``Slightly More Cultured Greedy'')}
	
	An attempt was made to introduce nondeterminism in the previously mentioned greedy algorithm. This was achieved by randomizing the order in which time slots are examined: again, this never yielded a single feasible solution, even after hundreds of runs.
	
	\subsection{Greedy 3 (``Timeslots and Conflicts'')}
	
	We tried sorting exams by some more meaningful criteria than their ID, and then assigning a random available time slot to each exam in that order.
	
	Initially we sorted them by number of conflicting exams. This solution was simple but found feasible solutions only for \textit{instance01}, so we decided to sort them first by the number of unavailable timeslots (timeslots with conflicting exams already scheduled), then by the number of conflicts. Since the order depends on current solution (each time an exam is scheduled, the ``number of unavailable timeslots'' for some other exams change), the list needed to be sorted again at each step.
	
	\begin{algorithm}[H]
%		%\KwData{dati}
%		%\KwResult{risultato}
%		%initialization\;
		$list \gets \text{all exams to be scheduled, sorted by }\textit{(number of unavailable slot, number of conflicts)}$\;
		\While{$list\text{ is not empty}$}{
			$E \gets \textit{ first element from }list$\;
			$T \gets \textit{ random available timeslot}$\;
			schedule $E$ in $T$\;
			remove $E$ from $list$\;
			sort $list$ again\;
		}	
		\caption{Algorithm with Timeslots and Conflicts sorting}
	\end{algorithm}

	But even so, there were still no feasible solutions for the other instances.
	
	\subsection{Greedy 4 (``Timeslots, Conflicts and Unscheduling'')}
	
	With the previous algorithm, the tipping point was the absence of available timeslost for the current exam when getting near the end of the list.
	
	So we decided to unschedule all the conflicting exams of the current one when that situation was encountered, sort and retry scheduling them again.
	
	In order to avoid unstable or ``oscillating'' situations, we fixed a maximum number of ``retires'': if this limit is exceeded, the algorithm returns anyway leaving an infeasible solution, which will be discarded and another attempt will be made, from a different initial solution. This was a great step forward, as it worked with all instances. There was only one problem: in more complex instance it takes more time to get a feasible solution.
	
	\begin{algorithm}[H]
%		$backup \gets \text{current solution (even an empty one)}$\;
%		$sol \gets \text{current solution (even an empty one)}$\;
		$I \gets 0$\;
		$list \gets \text{all exams to be scheduled, sorted by }\textit{(number of unavailable slot, number of conflicts)}$\;
		\While{$list$ is not empty}{
			\If{\textit{I} >= limit}{
				\Return{no feasible solution found}\;
%				$sol \gets backup$\;
%				restart the alogithm\;
			}
			$E \gets \textit{ first element from }list$\;
			$T \gets \textit{ random available timeslot}$\;
			\eIf{$T$ is valid (not null)}{
				schedule $E$ in $T$\;
				remove $E$ from $list$\;
			}{
				\ForEach{conflicting exam $C$ of $E$}{
					unschedule $C$\;
				}
				$I \gets I + 1$\;
			}
			sort $list$ again\;
		}
		\Return{feasible solution found}\;
		\caption{First Feasible Solution algorithm}
	\end{algorithm}
	
	 This was a great step forward, working with all instances. There was only one problem: in larger instances, like \textit{instance06}, it took a lot of time to generate an initial solution.
	
	\subsection{Greedy 5 (``Cached Timeslots, Conflicts and Unscheduling'')}
	
	We used a profiler multiple times to optimize the code of our program and find performance bottlenecks: while most optimizations are implementation details (e.g. using \textsc{HashMap}s with low load factors instead of \textsc{TreeMap}s), this one is almost algorithmic: when sorting $list$, the ``number of unavailable timeslots'' had to be computed each time, since it depends on which exams are currently scheduled or not.
	
	That required, for each exam, to iterate over its conflicting exams, checking if and were are they scheduled, which is a slow procedure.
	
	The problem is that, being part of a comparison function, it was run approximately $2\cdot n \log(n)$ times ($n \log(n)$ comparisons between 2 exams), $n$ being length of $list$. So we implemented a ``caching layer'' that stores the computed number of unavailable time slots in an hash map, so the slow computation is run exactly $n$ times and the remaing times a fast $\mathrm{O}(1)$ hash map access (cache hit) is used. The cache has to always be reset before sorting, since we deemed too complicated keeping it updated.
	
	This, coupled to a few other tweaks, brought down the average time for each run of the algorithm from 360 ms to 120 ms. Considering it was run hundreds of times in each thread, it is a considerable improvement.
	
	These are all successive improvements of the same algorithm, so in the end this is the only one we used.
	
	\section{Further solutions generation}
	
	\subsection{Genetic algorithm}
	
	We tried running a genetic algorithm implementation, with ``Random'' and ``Greedy 2'' initial solutions especially. It worked fine on the test instance, reaching the optimum solution in around 5-10 iterations with single-point crossover and a mutation (assigning a random time slot to an exam) probability of $0.1$, however on real instances it never produced a feasible solution, not even after thousands of iterations.
	
	\subsection{Simulated Annealing 1}
	\label{neighbors}
	
	We decided to use a simulated annealing algorithm, implemented in its most standard form, as a starting point.
	
	\subsubsection{Temperature, probability and delta}
	
	Probability is calculated according to the standard formula: $exp\left(\frac{\mathrm{currentCost}-\mathrm{neighborCost}}{\mathrm{temperature}}\right)$.
	
	Temperature is calculated according to qualcosa, il delta according to qualcosa pure lui.
	
	\subsubsection{Neighbor generation}
	
	Nieghbor solutions are generated by taking the current (feasible) solution, unscheduling a percentage of all the exams and rescheduling them with ``Greedy 4'' and later ``Greedy 5'' algorithm.
	
	After some experiments, we found that unscheduling between $20\%$ and $30\%$ of exams gave the best and most consistent results, unscheduling around $10\%$ sometimes gave exceptional solution while other times some horrible ones, while unscheduling more than $50\%$ of exams was too slow on larger instances.
	
	Ultimately we settled on sarting from $30\%$ and decreasing the percentage as time goes on according to temperature. We also placed a lower limit of $10\%$: if calculated percentage is less than $10\%$, it is set to $10\%$. This makes the decrease nonlinear, but doesn't really seem to affect the generated solutions in a bad way and it was easy to code.
	
	Since the two Greedy algorithms may fail, when that happens neighbor generation is retried with a different set of unscheduled exams. This happens very rarely in all instances, but very often in \textit{instance02}.
	
	\subsection{Simulated annealing 2}
	
	We enhanced simulated annealing 1 by adding a local search on each generated solution (initial or neighbor). Our local search works like this:
	
	\begin{algorithm}[H]
		%		$sol \gets \text{current solution (even an empty one)}$\;
		$list \gets \text{all exams to be scheduled, sorted by }\textit{number of conflicts}$\;
		\ForEach{exam $E$ in $list$}{
			$T \gets \text{timeslot where }E\text{ is scheduled}$\;
			$C \gets \text{cost of exam }E\text{ in }T\text{ time slot according to objective function}$\;
			\ForEach{timeslot $T'\neq T$}{
				$C' \gets \text{cost of exam }E\text{ in }T'\text{ time slot according to objective function}$\;
				\If{$C'<C$}{
					schedule $E$ in $T'$\;
					$C \gets C'$\;
				}
			}
		}
		\caption{Local search}
	\end{algorithm}

	since each time an exam is rescheduled the cost (penalty) of any other exam may change, but the algorithm runs over exams only once, it may provide better optimizations if run multiple times. We exploited this fact by placing a minimum improvement percentage: if after each run the solution has improved by more than the minimum percentage, run local search again. The higher the required minimum improvement, the less times local search will be run.
	
	After some testing, we found that $10\%$ was a good starting point for initial solutions, as in most cases ran local search exactly once and yielded a solution better by around $5\%$ to $9\%$, which helped simulated annealing to get an even better solution sooner.
	
	We also decided to run local search on generated neighbors too, as often they were far worse than an optimized initial solution and so were never picked as ``better'' by simulated annealing. There, we started from $10\%$ and decreased the minimum improvement percentage linearly as time goes on, until almost $0\%$: in our testing we found that, even with percentages as low as $0.001\%$, local search terminates in at most 4 or 5 iterations, so there was no risk of letting the algorithm run forever.
	
	Our local search has linear time complexity in the number of exams, since time slots are always far less than exams, so it's very fast. Sorting exams isn't really done by this algorithm, as the values are computed when reading initial data and cannot change as the program runs.
	
	\subsection{Simulated annealing 3 (``Mutant Simulated Annealing\texttrademark'')}
	
	
	
	
\end{document}
